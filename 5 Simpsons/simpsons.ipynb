{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list a ll files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-15T12:18:22.236812Z","iopub.execute_input":"2021-11-15T12:18:22.237189Z","iopub.status.idle":"2021-11-15T12:18:22.260813Z","shell.execute_reply.started":"2021-11-15T12:18:22.237104Z","shell.execute_reply":"2021-11-15T12:18:22.259670Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\n\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:22.263460Z","iopub.execute_input":"2021-11-15T12:18:22.263794Z","iopub.status.idle":"2021-11-15T12:18:23.726942Z","shell.execute_reply.started":"2021-11-15T12:18:22.263738Z","shell.execute_reply":"2021-11-15T12:18:23.725601Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi\nimport torch\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:23.728570Z","iopub.execute_input":"2021-11-15T12:18:23.728996Z","iopub.status.idle":"2021-11-15T12:18:24.528278Z","shell.execute_reply.started":"2021-11-15T12:18:23.728936Z","shell.execute_reply":"2021-11-15T12:18:24.526949Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport numpy as np\nfrom skimage import io\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom PIL import Image\nfrom pathlib import Path\n\nfrom torchvision import transforms\nfrom multiprocessing.pool import ThreadPool\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\n\nfrom matplotlib import colors, pyplot as plt\n%matplotlib inline\n\n# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n# мы будем игнорировать warnings\nimport warnings\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:24.530345Z","iopub.execute_input":"2021-11-15T12:18:24.530629Z","iopub.status.idle":"2021-11-15T12:18:26.284084Z","shell.execute_reply.started":"2021-11-15T12:18:24.530587Z","shell.execute_reply":"2021-11-15T12:18:26.282978Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# разные режимы датасета \nDATA_MODES = ['train', 'val', 'test']\n# все изображения будут масштабированы к размеру 224x224 px\nRESCALE_SIZE = 224\n# работаем на видеокарте\nDEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:26.287832Z","iopub.execute_input":"2021-11-15T12:18:26.288399Z","iopub.status.idle":"2021-11-15T12:18:26.298240Z","shell.execute_reply.started":"2021-11-15T12:18:26.288351Z","shell.execute_reply":"2021-11-15T12:18:26.297080Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class SimpsonsDataset(Dataset):\n    \"\"\"\n    Датасет с картинками, который паралельно подгружает их из папок\n    производит скалирование и превращение в торчевые тензоры\n    \"\"\"\n    def __init__(self, files, mode):\n        super().__init__()\n        # список файлов для загрузки\n        self.files = sorted(files)\n        # режим работы\n        self.mode = mode\n\n        if self.mode not in DATA_MODES:\n            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n            raise NameError\n\n        self.len_ = len(self.files)\n     \n        self.label_encoder = LabelEncoder()\n\n        if self.mode != 'test':\n            self.labels = [path.parent.name for path in self.files]\n            self.label_encoder.fit(self.labels)\n\n            with open('label_encoder.pkl', 'wb') as le_dump_file:\n                  pickle.dump(self.label_encoder, le_dump_file)\n                      \n    def __len__(self):\n        return self.len_\n      \n    def load_sample(self, file):\n        image = Image.open(file)\n        image.load()\n        return image\n  \n    def __getitem__(self, index):\n        # для преобразования изображений в тензоры PyTorch и нормализации входа\n        if self.mode == 'train': \n            transform = transforms.Compose([\n                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n                transforms.RandomRotation(degrees=30),\n                transforms.RandomHorizontalFlip(),\n#                 transforms.ColorJitter(hue=.1, saturation=.1),\n#                 transforms.RandomAdjustSharpness(0, p=0.5),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n            ])\n        else:  \n            transform = transforms.Compose([\n                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n            ])\n        x = self.load_sample(self.files[index])\n        x = transform(x)\n        if self.mode == 'test':\n            return x\n        else:\n            label = self.labels[index]\n            label_id = self.label_encoder.transform([label])\n            y = label_id.item()\n            return x, y\n        \n#     def _prepare_sample(self, image):\n#         image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n#         return np.array(image)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:26.299728Z","iopub.execute_input":"2021-11-15T12:18:26.300303Z","iopub.status.idle":"2021-11-15T12:18:26.322571Z","shell.execute_reply.started":"2021-11-15T12:18:26.300258Z","shell.execute_reply":"2021-11-15T12:18:26.321223Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def imshow(inp, title=None, plt_ax=plt, default=False):\n    \"\"\"Imshow для тензоров\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt_ax.imshow(inp)\n    if title is not None:\n        plt_ax.set_title(title)\n    plt_ax.grid(False)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:26.324154Z","iopub.execute_input":"2021-11-15T12:18:26.325587Z","iopub.status.idle":"2021-11-15T12:18:26.336556Z","shell.execute_reply.started":"2021-11-15T12:18:26.325539Z","shell.execute_reply":"2021-11-15T12:18:26.335542Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"Path('train/simpsons_dataset')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:26.338470Z","iopub.execute_input":"2021-11-15T12:18:26.339556Z","iopub.status.idle":"2021-11-15T12:18:26.350646Z","shell.execute_reply.started":"2021-11-15T12:18:26.339458Z","shell.execute_reply":"2021-11-15T12:18:26.349544Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = Path(r'../input/journey-springfield/train/simpsons_dataset')\nTEST_DIR = Path(r'../input/journey-springfield/testset/testset')\n\ntrain_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\ntest_files = sorted(list(TEST_DIR.rglob('*.jpg')))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:26.352392Z","iopub.execute_input":"2021-11-15T12:18:26.352791Z","iopub.status.idle":"2021-11-15T12:18:31.227753Z","shell.execute_reply.started":"2021-11-15T12:18:26.352742Z","shell.execute_reply":"2021-11-15T12:18:31.226803Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Ниже мы исспользуем враппер над датасетом для удобной работы. Вам стоит понимать, что происходит с LabelEncoder и  с torch.Transformation. \n## ToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:\n## $input = \\frac{input - \\mu}{\\text{standard deviation}} $, <br>       константы - средние и дисперсии по каналам на основе ImageNet\n## Стоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.\n##  Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample) ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_val_labels = [path.parent.name for path in train_val_files]\ntrain_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n                                          stratify=train_val_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.229438Z","iopub.execute_input":"2021-11-15T12:18:31.229935Z","iopub.status.idle":"2021-11-15T12:18:31.358931Z","shell.execute_reply.started":"2021-11-15T12:18:31.229871Z","shell.execute_reply":"2021-11-15T12:18:31.357763Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"val_dataset = SimpsonsDataset(val_files, mode='val')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.361249Z","iopub.execute_input":"2021-11-15T12:18:31.361808Z","iopub.status.idle":"2021-11-15T12:18:31.425103Z","shell.execute_reply.started":"2021-11-15T12:18:31.361764Z","shell.execute_reply":"2021-11-15T12:18:31.423820Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset = SimpsonsDataset(train_files, mode='train')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.429184Z","iopub.execute_input":"2021-11-15T12:18:31.429469Z","iopub.status.idle":"2021-11-15T12:18:31.617716Z","shell.execute_reply.started":"2021-11-15T12:18:31.429422Z","shell.execute_reply":"2021-11-15T12:18:31.616572Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"pd.Series(train_dataset.labels).value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.619424Z","iopub.execute_input":"2021-11-15T12:18:31.619727Z","iopub.status.idle":"2021-11-15T12:18:31.641990Z","shell.execute_reply.started":"2021-11-15T12:18:31.619687Z","shell.execute_reply":"2021-11-15T12:18:31.640733Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"pd.Series(train_val_labels).value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.649112Z","iopub.execute_input":"2021-11-15T12:18:31.649347Z","iopub.status.idle":"2021-11-15T12:18:31.663527Z","shell.execute_reply.started":"2021-11-15T12:18:31.649317Z","shell.execute_reply":"2021-11-15T12:18:31.662462Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# mean_count = round(pd.Series(train_val_labels).value_counts().mean())\n# median_count = round(pd.Series(train_val_labels).value_counts().median())","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.665696Z","iopub.execute_input":"2021-11-15T12:18:31.666389Z","iopub.status.idle":"2021-11-15T12:18:31.672336Z","shell.execute_reply.started":"2021-11-15T12:18:31.666344Z","shell.execute_reply":"2021-11-15T12:18:31.671252Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Наблюдаем дисбаланс классов, что плохо повлияет на нашу модель. Cтоит применить аугментации. И увеличить количество классов ниже медианного или среднего до медианного или среднего. (Лучше всего показал результат 100)","metadata":{}},{"cell_type":"code","source":"def make_dict_paths(train_files, train_labels):\n    dct = {}\n    for label in np.unique(train_labels):\n        dct[label] = []\n    \n    for path, label in zip(train_files, train_labels):\n        dct[label].append(path)\n    return dct\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.706324Z","iopub.execute_input":"2021-11-15T12:18:31.707118Z","iopub.status.idle":"2021-11-15T12:18:31.714214Z","shell.execute_reply.started":"2021-11-15T12:18:31.707057Z","shell.execute_reply":"2021-11-15T12:18:31.713018Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"dict_persons_train = make_dict_paths(train_files, train_dataset.labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.715814Z","iopub.execute_input":"2021-11-15T12:18:31.716597Z","iopub.status.idle":"2021-11-15T12:18:31.736422Z","shell.execute_reply.started":"2021-11-15T12:18:31.716550Z","shell.execute_reply":"2021-11-15T12:18:31.735521Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for person in dict_persons_train:\n    if len(dict_persons_train[person]) < 100:\n        dict_persons_train[person] = dict_persons_train[person] * (100 // len(dict_persons_train[person]))\n        dict_persons_train[person].extend(dict_persons_train[person][:100 - len(dict_persons_train[person])])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.737901Z","iopub.execute_input":"2021-11-15T12:18:31.738873Z","iopub.status.idle":"2021-11-15T12:18:31.746670Z","shell.execute_reply.started":"2021-11-15T12:18:31.738829Z","shell.execute_reply":"2021-11-15T12:18:31.745353Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"for person in dict_persons_train:\n    print(f\"{person}\\t{len(dict_persons_train[person])}\")\nnew_train_files = []\n\nfor person in dict_persons_train:\n    new_train_files.extend(dict_persons_train[person])","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.760280Z","iopub.execute_input":"2021-11-15T12:18:31.761523Z","iopub.status.idle":"2021-11-15T12:18:31.780643Z","shell.execute_reply.started":"2021-11-15T12:18:31.761474Z","shell.execute_reply":"2021-11-15T12:18:31.779768Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Давайте посмотрим на наших героев внутри датасета.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(10, 10), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = train_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:31.782063Z","iopub.execute_input":"2021-11-15T12:18:31.782450Z","iopub.status.idle":"2021-11-15T12:18:33.578056Z","shell.execute_reply.started":"2021-11-15T12:18:31.782407Z","shell.execute_reply":"2021-11-15T12:18:33.577144Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(10, 10), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:33.579339Z","iopub.execute_input":"2021-11-15T12:18:33.580008Z","iopub.status.idle":"2021-11-15T12:18:35.254125Z","shell.execute_reply.started":"2021-11-15T12:18:33.579664Z","shell.execute_reply":"2021-11-15T12:18:35.253222Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Построение нейросети\n\nЗапустить данную сеть будет вашим мини-заданием на первую неделю, чтобы было проще участвовать в соревновании.\n\nДанная архитектура будет очень простой и нужна для того, чтобы установить базовое понимание и получить простенький сабмит на Kaggle\n\n<!-- Здесь вам предлагается дописать сверточную сеть глубины 4/5.  -->\n\n*Описание слоев*:\n\n\n\n1. размерность входа: 3x224x224 \n2.размерности после слоя:  8x111x111\n3. 16x54x54\n4. 32x26x26\n5. 64x12x12\n6. выход: 96x5x5","metadata":{}},{"cell_type":"code","source":"# Очень простая сеть\nclass SimpleCnn(nn.Module):\n  \n    def __init__(self, n_classes):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.conv5 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        \n        self.out = nn.Linear(96 * 5 * 5, n_classes)\n  \n  \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n\n        x = x.view(x.size(0), -1)\n        logits = self.out(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:35.255844Z","iopub.execute_input":"2021-11-15T12:18:35.256526Z","iopub.status.idle":"2021-11-15T12:18:35.274616Z","shell.execute_reply.started":"2021-11-15T12:18:35.256469Z","shell.execute_reply":"2021-11-15T12:18:35.273444Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def fit_epoch(model, train_loader, criterion, optimizer):\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n  \n    for inputs, labels in train_loader:\n        inputs = inputs.to(DEVICE)\n        labels = labels.to(DEVICE)\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        preds = torch.argmax(outputs, 1)\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_data += inputs.size(0)\n              \n    train_loss = running_loss / processed_data\n    train_acc = running_corrects.cpu().numpy() / processed_data\n    return train_loss, train_acc","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:35.278590Z","iopub.execute_input":"2021-11-15T12:18:35.278919Z","iopub.status.idle":"2021-11-15T12:18:35.289936Z","shell.execute_reply.started":"2021-11-15T12:18:35.278871Z","shell.execute_reply":"2021-11-15T12:18:35.288873Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def eval_epoch(model, val_loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    processed_size = 0\n\n    for inputs, labels in val_loader:\n        inputs = inputs.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            preds = torch.argmax(outputs, 1)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_size += inputs.size(0)\n    val_loss = running_loss / processed_size\n    val_acc = running_corrects.double() / processed_size\n    return val_loss, val_acc","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:35.292027Z","iopub.execute_input":"2021-11-15T12:18:35.293091Z","iopub.status.idle":"2021-11-15T12:18:35.305608Z","shell.execute_reply.started":"2021-11-15T12:18:35.293043Z","shell.execute_reply":"2021-11-15T12:18:35.304238Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def train(train_files, val_files, model, epochs, batch_size):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n\n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        opt = torch.optim.Adam(model.parameters())\n        criterion = nn.CrossEntropyLoss()\n\n        for epoch in range(epochs):\n            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n            print(\"loss\", train_loss)\n            \n            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n            history.append((train_loss, train_acc, val_loss, val_acc))\n            \n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n            \n    return history","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:35.307440Z","iopub.execute_input":"2021-11-15T12:18:35.308111Z","iopub.status.idle":"2021-11-15T12:18:35.320185Z","shell.execute_reply.started":"2021-11-15T12:18:35.308064Z","shell.execute_reply":"2021-11-15T12:18:35.318962Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_loader):\n    with torch.no_grad():\n        logits = []\n    \n        for inputs in test_loader:\n            inputs = inputs.to(DEVICE)\n            model.eval()\n            outputs = model(inputs).cpu()\n            logits.append(outputs)\n            \n    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:35.322648Z","iopub.execute_input":"2021-11-15T12:18:35.324894Z","iopub.status.idle":"2021-11-15T12:18:35.334800Z","shell.execute_reply.started":"2021-11-15T12:18:35.324847Z","shell.execute_reply":"2021-11-15T12:18:35.333671Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"n_classes = len(np.unique(train_val_labels))\nsimple_cnn = SimpleCnn(n_classes).to(DEVICE)\nprint(\"we will classify :{}\".format(n_classes))\nprint(simple_cnn)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:35.336444Z","iopub.execute_input":"2021-11-15T12:18:35.337323Z","iopub.status.idle":"2021-11-15T12:18:38.725415Z","shell.execute_reply.started":"2021-11-15T12:18:35.337258Z","shell.execute_reply":"2021-11-15T12:18:38.724293Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Запустим обучение сети.","metadata":{}},{"cell_type":"code","source":"if val_dataset is None:\n    val_dataset = SimpsonsDataset(val_files, mode='val')\n    \n# train_dataset = SimpsonsDataset(train_files, mode='train')\ntrain_dataset = SimpsonsDataset(new_train_files, mode='train')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:38.727267Z","iopub.execute_input":"2021-11-15T12:18:38.727578Z","iopub.status.idle":"2021-11-15T12:18:38.930416Z","shell.execute_reply.started":"2021-11-15T12:18:38.727535Z","shell.execute_reply":"2021-11-15T12:18:38.929434Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"history = train(train_dataset, val_dataset, model=simple_cnn, epochs=2, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:18:38.932164Z","iopub.execute_input":"2021-11-15T12:18:38.932463Z","iopub.status.idle":"2021-11-15T12:25:36.166423Z","shell.execute_reply.started":"2021-11-15T12:18:38.932422Z","shell.execute_reply":"2021-11-15T12:25:36.165485Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# history = train(train_dataset, val_dataset, model=simple_cnn, epochs=2, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:36.168541Z","iopub.execute_input":"2021-11-15T12:25:36.169125Z","iopub.status.idle":"2021-11-15T12:25:36.175367Z","shell.execute_reply.started":"2021-11-15T12:25:36.169081Z","shell.execute_reply":"2021-11-15T12:25:36.174124Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"loss, acc, val_loss, val_acc = zip(*history)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:36.177003Z","iopub.execute_input":"2021-11-15T12:25:36.177639Z","iopub.status.idle":"2021-11-15T12:25:36.189688Z","shell.execute_reply.started":"2021-11-15T12:25:36.177578Z","shell.execute_reply":"2021-11-15T12:25:36.188402Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\nplt.plot(loss, label=\"train_loss\")\nplt.plot(val_loss, label=\"val_loss\")\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:36.191553Z","iopub.execute_input":"2021-11-15T12:25:36.192109Z","iopub.status.idle":"2021-11-15T12:25:36.490927Z","shell.execute_reply.started":"2021-11-15T12:25:36.192017Z","shell.execute_reply":"2021-11-15T12:25:36.489883Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Хорошо бы понять, как сделать сабмит. У нас есть сеть и методы eval у нее, которые позволяют перевести сеть в режим предсказания. Стоит понимать, что у нашей модели на последнем слое стоит softmax, которые позволяет получить вектор вероятностей того, что объект относится к тому или иному классу. Давайте воспользуемся этим.","metadata":{}},{"cell_type":"code","source":"def predict_one_sample(model, inputs, device=DEVICE):\n    \"\"\"Предсказание, для одной картинки\"\"\"\n    with torch.no_grad():\n        inputs = inputs.to(device)\n        model.eval()\n        logit = model(inputs).cpu()\n        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:36.492359Z","iopub.execute_input":"2021-11-15T12:25:36.492743Z","iopub.status.idle":"2021-11-15T12:25:36.501806Z","shell.execute_reply.started":"2021-11-15T12:25:36.492669Z","shell.execute_reply":"2021-11-15T12:25:36.500164Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"random_characters = int(np.random.uniform(0,1000))\nex_img, true_label = val_dataset[random_characters]\nprobs_im = predict_one_sample(simple_cnn, ex_img.unsqueeze(0))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:36.504458Z","iopub.execute_input":"2021-11-15T12:25:36.504887Z","iopub.status.idle":"2021-11-15T12:25:36.536819Z","shell.execute_reply.started":"2021-11-15T12:25:36.504838Z","shell.execute_reply":"2021-11-15T12:25:36.535844Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"idxs = list(map(int, np.random.uniform(0,1000, 20)))\nimgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n\nprobs_ims = predict(simple_cnn, imgs)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:36.540698Z","iopub.execute_input":"2021-11-15T12:25:36.541295Z","iopub.status.idle":"2021-11-15T12:25:36.716496Z","shell.execute_reply.started":"2021-11-15T12:25:36.541253Z","shell.execute_reply":"2021-11-15T12:25:36.715374Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:36.719262Z","iopub.execute_input":"2021-11-15T12:25:36.719842Z","iopub.status.idle":"2021-11-15T12:25:36.725951Z","shell.execute_reply.started":"2021-11-15T12:25:36.719797Z","shell.execute_reply":"2021-11-15T12:25:36.724714Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(probs_ims,-1)\n\nactual_labels = [val_dataset[id][1] for id in idxs]\n\n# preds_class = [label_encoder.classes_[i] for i in y_pred]","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:36.727832Z","iopub.execute_input":"2021-11-15T12:25:36.728238Z","iopub.status.idle":"2021-11-15T12:25:36.855349Z","shell.execute_reply.started":"2021-11-15T12:25:36.728196Z","shell.execute_reply":"2021-11-15T12:25:36.854445Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nf1_score(actual_labels, y_pred.tolist(),average='weighted')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:37.042105Z","iopub.execute_input":"2021-11-15T12:25:37.042773Z","iopub.status.idle":"2021-11-15T12:25:37.054754Z","shell.execute_reply.started":"2021-11-15T12:25:37.042738Z","shell.execute_reply":"2021-11-15T12:25:37.053246Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Сделаем классную визуализацию, чтобы посмотреть насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода.","metadata":{}},{"cell_type":"code","source":"import matplotlib.patches as patches\nfrom matplotlib.font_manager import FontProperties\n\nfig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    \n    \n\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)\n    \n    actual_text = \"Actual : {}\".format(img_label)\n            \n    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n    font0 = FontProperties()\n    font = font0.copy()\n    font.set_family(\"fantasy\")\n    prob_pred = predict_one_sample(simple_cnn, im_val.unsqueeze(0))\n    predicted_proba = np.max(prob_pred)*100\n    y_pred = np.argmax(prob_pred)\n    \n    predicted_label = label_encoder.classes_[y_pred]\n    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n            \n    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:37.057024Z","iopub.execute_input":"2021-11-15T12:25:37.057376Z","iopub.status.idle":"2021-11-15T12:25:39.280641Z","shell.execute_reply.started":"2021-11-15T12:25:37.057332Z","shell.execute_reply":"2021-11-15T12:25:39.278375Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## Попробуйте найти те классы, которые сеть не смогла расспознать. Изучите данную проблему, это понадобится в дальнейшем.","metadata":{}},{"cell_type":"code","source":"test_dataset = SimpsonsDataset(test_files, mode=\"test\")\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\nprobs = predict(simple_cnn, test_loader)\n\n\npreds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\ntest_filenames = [path.name for path in test_dataset.files]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:39.282411Z","iopub.execute_input":"2021-11-15T12:25:39.283289Z","iopub.status.idle":"2021-11-15T12:25:47.301750Z","shell.execute_reply.started":"2021-11-15T12:25:39.283251Z","shell.execute_reply":"2021-11-15T12:25:47.300766Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"d = {'Id':test_filenames, 'Expected':preds}\nsub_0 = pd.DataFrame(data=d)\nsub_0.to_csv('sub_0.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:47.304042Z","iopub.execute_input":"2021-11-15T12:25:47.304725Z","iopub.status.idle":"2021-11-15T12:25:47.312681Z","shell.execute_reply.started":"2021-11-15T12:25:47.304667Z","shell.execute_reply":"2021-11-15T12:25:47.311740Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('/kaggle/working/sub_0.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:47.335088Z","iopub.execute_input":"2021-11-15T12:25:47.335374Z","iopub.status.idle":"2021-11-15T12:25:47.359815Z","shell.execute_reply.started":"2021-11-15T12:25:47.335328Z","shell.execute_reply":"2021-11-15T12:25:47.358885Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"! ls ","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:47.361335Z","iopub.execute_input":"2021-11-15T12:25:47.361639Z","iopub.status.idle":"2021-11-15T12:25:48.169761Z","shell.execute_reply.started":"2021-11-15T12:25:47.361587Z","shell.execute_reply":"2021-11-15T12:25:48.168545Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Освободим кэж видеопамяти\ntorch.cuda.empty_cache() ","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:48.171874Z","iopub.execute_input":"2021-11-15T12:25:48.172521Z","iopub.status.idle":"2021-11-15T12:25:48.233674Z","shell.execute_reply.started":"2021-11-15T12:25:48.172456Z","shell.execute_reply":"2021-11-15T12:25:48.231653Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# GoogleNet","metadata":{}},{"cell_type":"code","source":"from torchvision import models","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:48.235799Z","iopub.execute_input":"2021-11-15T12:25:48.236420Z","iopub.status.idle":"2021-11-15T12:25:48.245089Z","shell.execute_reply.started":"2021-11-15T12:25:48.236369Z","shell.execute_reply":"2021-11-15T12:25:48.243801Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model_google = models.googlenet(pretrained=True).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:48.247225Z","iopub.execute_input":"2021-11-15T12:25:48.248008Z","iopub.status.idle":"2021-11-15T12:25:49.395997Z","shell.execute_reply.started":"2021-11-15T12:25:48.247961Z","shell.execute_reply":"2021-11-15T12:25:49.394478Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"child_counter = 0\nfor child in model_google.children():\n    print(\" child\", child_counter, \"is:\")\n    print(child)\n    child_counter += 1","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-15T12:25:49.399070Z","iopub.execute_input":"2021-11-15T12:25:49.400264Z","iopub.status.idle":"2021-11-15T12:25:49.448878Z","shell.execute_reply.started":"2021-11-15T12:25:49.400122Z","shell.execute_reply":"2021-11-15T12:25:49.444293Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Выключаем подсчет градиентов для слоев, которые не будем обучать\nfor i, child in enumerate(model_google.children()):\n    if i not in [x for x in range(9,17)]: # Заморозим первые 8 слоев\n        for param in child.parameters():\n            param.requires_grad = False\n\nmodel_google.fc = nn.Sequential(nn.Linear(1024,42))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:49.450862Z","iopub.execute_input":"2021-11-15T12:25:49.451231Z","iopub.status.idle":"2021-11-15T12:25:49.464000Z","shell.execute_reply.started":"2021-11-15T12:25:49.451188Z","shell.execute_reply":"2021-11-15T12:25:49.461333Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"model_google = model_google.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:49.470964Z","iopub.execute_input":"2021-11-15T12:25:49.472898Z","iopub.status.idle":"2021-11-15T12:25:49.496104Z","shell.execute_reply.started":"2021-11-15T12:25:49.472722Z","shell.execute_reply":"2021-11-15T12:25:49.495232Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"history = train(train_dataset, val_dataset, model=model_google, epochs=15,  \n                batch_size=64\n               )","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:49.497510Z","iopub.execute_input":"2021-11-15T12:25:49.497990Z","iopub.status.idle":"2021-11-15T13:09:17.868483Z","shell.execute_reply.started":"2021-11-15T12:25:49.497927Z","shell.execute_reply":"2021-11-15T13:09:17.867392Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"import copy\n\n# сохранить веса нашей нейросети model\nmodel_pre_weights = copy.deepcopy(model_google.state_dict())\ntorch.save(model_pre_weights, \"path_to\\\\model_pre_weights.pth\")\nmodel_google.load_state_dict(torch.load(\"path_to\\\\model_pre_weights.pth\"))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:17.870206Z","iopub.execute_input":"2021-11-15T13:09:17.870721Z","iopub.status.idle":"2021-11-15T13:09:18.085326Z","shell.execute_reply.started":"2021-11-15T13:09:17.870677Z","shell.execute_reply":"2021-11-15T13:09:18.084302Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# # Включаем все слои!!!\n# for child in model_google.children():\n#     for param in child.parameters():\n#         param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.087015Z","iopub.execute_input":"2021-11-15T13:09:18.087499Z","iopub.status.idle":"2021-11-15T13:09:18.093062Z","shell.execute_reply.started":"2021-11-15T13:09:18.087454Z","shell.execute_reply":"2021-11-15T13:09:18.091019Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.094857Z","iopub.execute_input":"2021-11-15T13:09:18.095463Z","iopub.status.idle":"2021-11-15T13:09:18.103952Z","shell.execute_reply.started":"2021-11-15T13:09:18.095418Z","shell.execute_reply":"2021-11-15T13:09:18.102836Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# history = train(train_dataset, val_dataset, model=model_google, epochs=19, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.105324Z","iopub.execute_input":"2021-11-15T13:09:18.105953Z","iopub.status.idle":"2021-11-15T13:09:18.115628Z","shell.execute_reply.started":"2021-11-15T13:09:18.105799Z","shell.execute_reply":"2021-11-15T13:09:18.114422Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# # сохранить веса нашей нейросети model\n# model_25epoch_weights = copy.deepcopy(model_google.state_dict())\n# torch.save(model_25epoch_weights, \"path_to\\\\model_25epoch_weights.pth\")","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.117096Z","iopub.execute_input":"2021-11-15T13:09:18.118097Z","iopub.status.idle":"2021-11-15T13:09:18.127111Z","shell.execute_reply.started":"2021-11-15T13:09:18.118053Z","shell.execute_reply":"2021-11-15T13:09:18.125989Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# # загружаем сохраненное состояние весов нейросети\n# model_google.load_state_dict(torch.load(\"path_to\\\\model_25epoch_weights.pth\"))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.131195Z","iopub.execute_input":"2021-11-15T13:09:18.131609Z","iopub.status.idle":"2021-11-15T13:09:18.137876Z","shell.execute_reply.started":"2021-11-15T13:09:18.131547Z","shell.execute_reply":"2021-11-15T13:09:18.136827Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"Заморозка первых слоев положительно сказывается на быстродействии и качестве модели.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\nplt.plot(loss, label=\"train_loss\")\nplt.plot(val_loss, label=\"val_loss\")\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.152394Z","iopub.execute_input":"2021-11-15T13:09:18.153707Z","iopub.status.idle":"2021-11-15T13:09:18.446731Z","shell.execute_reply.started":"2021-11-15T13:09:18.153660Z","shell.execute_reply":"2021-11-15T13:09:18.445822Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"probs_ims = predict(model_google, imgs)\ny_pred = np.argmax(probs_ims,-1)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.729308Z","iopub.execute_input":"2021-11-15T13:09:18.729642Z","iopub.status.idle":"2021-11-15T13:09:18.735520Z","shell.execute_reply.started":"2021-11-15T13:09:18.729599Z","shell.execute_reply":"2021-11-15T13:09:18.734330Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"f1_score(actual_labels, y_pred.tolist(),average='weighted')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.737340Z","iopub.execute_input":"2021-11-15T13:09:18.737829Z","iopub.status.idle":"2021-11-15T13:09:18.753162Z","shell.execute_reply.started":"2021-11-15T13:09:18.737784Z","shell.execute_reply":"2021-11-15T13:09:18.752092Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"## На довольно небольшом количестве эпох удалось получить достойный результат 0.95\n## На лидерборде выбили **0.96068**\n","metadata":{}},{"cell_type":"code","source":"label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.754932Z","iopub.execute_input":"2021-11-15T13:09:18.755307Z","iopub.status.idle":"2021-11-15T13:09:18.761180Z","shell.execute_reply.started":"2021-11-15T13:09:18.755251Z","shell.execute_reply":"2021-11-15T13:09:18.760215Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as patches\nfrom matplotlib.font_manager import FontProperties\n\nfig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    \n    \n\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)\n    \n    actual_text = \"Actual : {}\".format(img_label)\n            \n    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n    font0 = FontProperties()\n    font = font0.copy()\n    font.set_family(\"fantasy\")\n    prob_pred = predict_one_sample(model_google, im_val.unsqueeze(0))\n    predicted_proba = np.max(prob_pred)*100\n    y_pred = np.argmax(prob_pred)\n    \n    predicted_label = label_encoder.classes_[y_pred]\n    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n            \n    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:18.763073Z","iopub.execute_input":"2021-11-15T13:09:18.763807Z","iopub.status.idle":"2021-11-15T13:09:21.049643Z","shell.execute_reply.started":"2021-11-15T13:09:18.763760Z","shell.execute_reply":"2021-11-15T13:09:21.048795Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"test_dataset = SimpsonsDataset(test_files, mode=\"test\")\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\nprobs = predict(model_google, test_loader)\npreds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\ntest_filenames = [path.name for path in test_dataset.files]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:21.051287Z","iopub.execute_input":"2021-11-15T13:09:21.052263Z","iopub.status.idle":"2021-11-15T13:09:25.264894Z","shell.execute_reply.started":"2021-11-15T13:09:21.052208Z","shell.execute_reply":"2021-11-15T13:09:25.263978Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"# SUB","metadata":{}},{"cell_type":"code","source":"d = {'Id':test_filenames, 'Expected':preds}\nsub_1 = pd.DataFrame(data=d)\nsub_1.to_csv('sub_1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:25.266691Z","iopub.execute_input":"2021-11-15T13:09:25.267004Z","iopub.status.idle":"2021-11-15T13:09:25.275789Z","shell.execute_reply.started":"2021-11-15T13:09:25.266962Z","shell.execute_reply":"2021-11-15T13:09:25.274614Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('sub_1.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T13:09:25.291670Z","iopub.execute_input":"2021-11-15T13:09:25.292770Z","iopub.status.idle":"2021-11-15T13:09:25.311579Z","shell.execute_reply.started":"2021-11-15T13:09:25.292723Z","shell.execute_reply":"2021-11-15T13:09:25.310640Z"},"trusted":true},"execution_count":71,"outputs":[]}]}