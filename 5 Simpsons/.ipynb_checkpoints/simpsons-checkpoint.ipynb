{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:22.237189Z",
     "iopub.status.busy": "2021-11-15T12:18:22.236812Z",
     "iopub.status.idle": "2021-11-15T12:18:22.260813Z",
     "shell.execute_reply": "2021-11-15T12:18:22.259670Z",
     "shell.execute_reply.started": "2021-11-15T12:18:22.237104Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list a ll files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:22.263794Z",
     "iopub.status.busy": "2021-11-15T12:18:22.263460Z",
     "iopub.status.idle": "2021-11-15T12:18:23.726942Z",
     "shell.execute_reply": "2021-11-15T12:18:23.725601Z",
     "shell.execute_reply.started": "2021-11-15T12:18:22.263738Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:23.728996Z",
     "iopub.status.busy": "2021-11-15T12:18:23.728570Z",
     "iopub.status.idle": "2021-11-15T12:18:24.528278Z",
     "shell.execute_reply": "2021-11-15T12:18:24.526949Z",
     "shell.execute_reply.started": "2021-11-15T12:18:23.728936Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:24.530629Z",
     "iopub.status.busy": "2021-11-15T12:18:24.530345Z",
     "iopub.status.idle": "2021-11-15T12:18:26.284084Z",
     "shell.execute_reply": "2021-11-15T12:18:26.282978Z",
     "shell.execute_reply.started": "2021-11-15T12:18:24.530587Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n",
    "# мы будем игнорировать warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:26.288399Z",
     "iopub.status.busy": "2021-11-15T12:18:26.287832Z",
     "iopub.status.idle": "2021-11-15T12:18:26.298240Z",
     "shell.execute_reply": "2021-11-15T12:18:26.297080Z",
     "shell.execute_reply.started": "2021-11-15T12:18:26.288351Z"
    }
   },
   "outputs": [],
   "source": [
    "# разные режимы датасета \n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "# работаем на видеокарте\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:26.300303Z",
     "iopub.status.busy": "2021-11-15T12:18:26.299728Z",
     "iopub.status.idle": "2021-11-15T12:18:26.322571Z",
     "shell.execute_reply": "2021-11-15T12:18:26.321223Z",
     "shell.execute_reply.started": "2021-11-15T12:18:26.300258Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "     \n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                  pickle.dump(self.label_encoder, le_dump_file)\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "      \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        if self.mode == 'train': \n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n",
    "                transforms.RandomRotation(degrees=30),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "#                 transforms.ColorJitter(hue=.1, saturation=.1),\n",
    "#                 transforms.RandomAdjustSharpness(0, p=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            ])\n",
    "        else:  \n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            ])\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "        \n",
    "#     def _prepare_sample(self, image):\n",
    "#         image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "#         return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:26.325587Z",
     "iopub.status.busy": "2021-11-15T12:18:26.324154Z",
     "iopub.status.idle": "2021-11-15T12:18:26.336556Z",
     "shell.execute_reply": "2021-11-15T12:18:26.335542Z",
     "shell.execute_reply.started": "2021-11-15T12:18:26.325539Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:26.339556Z",
     "iopub.status.busy": "2021-11-15T12:18:26.338470Z",
     "iopub.status.idle": "2021-11-15T12:18:26.350646Z",
     "shell.execute_reply": "2021-11-15T12:18:26.349544Z",
     "shell.execute_reply.started": "2021-11-15T12:18:26.339458Z"
    }
   },
   "outputs": [],
   "source": [
    "Path('train/simpsons_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:26.352791Z",
     "iopub.status.busy": "2021-11-15T12:18:26.352392Z",
     "iopub.status.idle": "2021-11-15T12:18:31.227753Z",
     "shell.execute_reply": "2021-11-15T12:18:31.226803Z",
     "shell.execute_reply.started": "2021-11-15T12:18:26.352742Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path(r'../input/journey-springfield/train/simpsons_dataset')\n",
    "TEST_DIR = Path(r'../input/journey-springfield/testset/testset')\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ниже мы исспользуем враппер над датасетом для удобной работы. Вам стоит понимать, что происходит с LabelEncoder и  с torch.Transformation. \n",
    "## ToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:\n",
    "## $input = \\frac{input - \\mu}{\\text{standard deviation}} $, <br>       константы - средние и дисперсии по каналам на основе ImageNet\n",
    "## Стоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.\n",
    "##  Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.229935Z",
     "iopub.status.busy": "2021-11-15T12:18:31.229438Z",
     "iopub.status.idle": "2021-11-15T12:18:31.358931Z",
     "shell.execute_reply": "2021-11-15T12:18:31.357763Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.229871Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
    "                                          stratify=train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.361808Z",
     "iopub.status.busy": "2021-11-15T12:18:31.361249Z",
     "iopub.status.idle": "2021-11-15T12:18:31.425103Z",
     "shell.execute_reply": "2021-11-15T12:18:31.423820Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.361764Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = SimpsonsDataset(val_files, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.429469Z",
     "iopub.status.busy": "2021-11-15T12:18:31.429184Z",
     "iopub.status.idle": "2021-11-15T12:18:31.617716Z",
     "shell.execute_reply": "2021-11-15T12:18:31.616572Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.429422Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SimpsonsDataset(train_files, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.619727Z",
     "iopub.status.busy": "2021-11-15T12:18:31.619424Z",
     "iopub.status.idle": "2021-11-15T12:18:31.641990Z",
     "shell.execute_reply": "2021-11-15T12:18:31.640733Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.619687Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(train_dataset.labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.649347Z",
     "iopub.status.busy": "2021-11-15T12:18:31.649112Z",
     "iopub.status.idle": "2021-11-15T12:18:31.663527Z",
     "shell.execute_reply": "2021-11-15T12:18:31.662462Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.649317Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(train_val_labels).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.666389Z",
     "iopub.status.busy": "2021-11-15T12:18:31.665696Z",
     "iopub.status.idle": "2021-11-15T12:18:31.672336Z",
     "shell.execute_reply": "2021-11-15T12:18:31.671252Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.666344Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean_count = round(pd.Series(train_val_labels).value_counts().mean())\n",
    "# median_count = round(pd.Series(train_val_labels).value_counts().median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наблюдаем дисбаланс классов, что плохо повлияет на нашу модель. Cтоит применить аугментации. И увеличить количество классов ниже медианного или среднего до медианного или среднего. (Лучше всего показал результат 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.707118Z",
     "iopub.status.busy": "2021-11-15T12:18:31.706324Z",
     "iopub.status.idle": "2021-11-15T12:18:31.714214Z",
     "shell.execute_reply": "2021-11-15T12:18:31.713018Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.707057Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_dict_paths(train_files, train_labels):\n",
    "    dct = {}\n",
    "    for label in np.unique(train_labels):\n",
    "        dct[label] = []\n",
    "    \n",
    "    for path, label in zip(train_files, train_labels):\n",
    "        dct[label].append(path)\n",
    "    return dct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.716597Z",
     "iopub.status.busy": "2021-11-15T12:18:31.715814Z",
     "iopub.status.idle": "2021-11-15T12:18:31.736422Z",
     "shell.execute_reply": "2021-11-15T12:18:31.735521Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.716550Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_persons_train = make_dict_paths(train_files, train_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.738873Z",
     "iopub.status.busy": "2021-11-15T12:18:31.737901Z",
     "iopub.status.idle": "2021-11-15T12:18:31.746670Z",
     "shell.execute_reply": "2021-11-15T12:18:31.745353Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.738829Z"
    }
   },
   "outputs": [],
   "source": [
    "for person in dict_persons_train:\n",
    "    if len(dict_persons_train[person]) < 100:\n",
    "        dict_persons_train[person] = dict_persons_train[person] * (100 // len(dict_persons_train[person]))\n",
    "        dict_persons_train[person].extend(dict_persons_train[person][:100 - len(dict_persons_train[person])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.761523Z",
     "iopub.status.busy": "2021-11-15T12:18:31.760280Z",
     "iopub.status.idle": "2021-11-15T12:18:31.780643Z",
     "shell.execute_reply": "2021-11-15T12:18:31.779768Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.761474Z"
    }
   },
   "outputs": [],
   "source": [
    "for person in dict_persons_train:\n",
    "    print(f\"{person}\\t{len(dict_persons_train[person])}\")\n",
    "new_train_files = []\n",
    "\n",
    "for person in dict_persons_train:\n",
    "    new_train_files.extend(dict_persons_train[person])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Давайте посмотрим на наших героев внутри датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:31.782450Z",
     "iopub.status.busy": "2021-11-15T12:18:31.782063Z",
     "iopub.status.idle": "2021-11-15T12:18:33.578056Z",
     "shell.execute_reply": "2021-11-15T12:18:33.577144Z",
     "shell.execute_reply.started": "2021-11-15T12:18:31.782407Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(10, 10), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1000))\n",
    "    im_val, label = train_dataset[random_characters]\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:33.580008Z",
     "iopub.status.busy": "2021-11-15T12:18:33.579339Z",
     "iopub.status.idle": "2021-11-15T12:18:35.254125Z",
     "shell.execute_reply": "2021-11-15T12:18:35.253222Z",
     "shell.execute_reply.started": "2021-11-15T12:18:33.579664Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(10, 10), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1000))\n",
    "    im_val, label = val_dataset[random_characters]\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение нейросети\n",
    "\n",
    "Запустить данную сеть будет вашим мини-заданием на первую неделю, чтобы было проще участвовать в соревновании.\n",
    "\n",
    "Данная архитектура будет очень простой и нужна для того, чтобы установить базовое понимание и получить простенький сабмит на Kaggle\n",
    "\n",
    "<!-- Здесь вам предлагается дописать сверточную сеть глубины 4/5.  -->\n",
    "\n",
    "*Описание слоев*:\n",
    "\n",
    "\n",
    "\n",
    "1. размерность входа: 3x224x224 \n",
    "2.размерности после слоя:  8x111x111\n",
    "3. 16x54x54\n",
    "4. 32x26x26\n",
    "5. 64x12x12\n",
    "6. выход: 96x5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:35.256526Z",
     "iopub.status.busy": "2021-11-15T12:18:35.255844Z",
     "iopub.status.idle": "2021-11-15T12:18:35.274616Z",
     "shell.execute_reply": "2021-11-15T12:18:35.273444Z",
     "shell.execute_reply.started": "2021-11-15T12:18:35.256469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Очень простая сеть\n",
    "class SimpleCnn(nn.Module):\n",
    "  \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(96 * 5 * 5, n_classes)\n",
    "  \n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.out(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:35.278919Z",
     "iopub.status.busy": "2021-11-15T12:18:35.278590Z",
     "iopub.status.idle": "2021-11-15T12:18:35.289936Z",
     "shell.execute_reply": "2021-11-15T12:18:35.288873Z",
     "shell.execute_reply.started": "2021-11-15T12:18:35.278871Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:35.293091Z",
     "iopub.status.busy": "2021-11-15T12:18:35.292027Z",
     "iopub.status.idle": "2021-11-15T12:18:35.305608Z",
     "shell.execute_reply": "2021-11-15T12:18:35.304238Z",
     "shell.execute_reply.started": "2021-11-15T12:18:35.293043Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_size += inputs.size(0)\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.double() / processed_size\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:35.308111Z",
     "iopub.status.busy": "2021-11-15T12:18:35.307440Z",
     "iopub.status.idle": "2021-11-15T12:18:35.320185Z",
     "shell.execute_reply": "2021-11-15T12:18:35.318962Z",
     "shell.execute_reply.started": "2021-11-15T12:18:35.308064Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_files, val_files, model, epochs, batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        opt = torch.optim.Adam(model.parameters())\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
    "            print(\"loss\", train_loss)\n",
    "            \n",
    "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
    "            \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:35.324894Z",
     "iopub.status.busy": "2021-11-15T12:18:35.322648Z",
     "iopub.status.idle": "2021-11-15T12:18:35.334800Z",
     "shell.execute_reply": "2021-11-15T12:18:35.333671Z",
     "shell.execute_reply.started": "2021-11-15T12:18:35.324847Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "    \n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            \n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:35.337323Z",
     "iopub.status.busy": "2021-11-15T12:18:35.336444Z",
     "iopub.status.idle": "2021-11-15T12:18:38.725415Z",
     "shell.execute_reply": "2021-11-15T12:18:38.724293Z",
     "shell.execute_reply.started": "2021-11-15T12:18:35.337258Z"
    }
   },
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(train_val_labels))\n",
    "simple_cnn = SimpleCnn(n_classes).to(DEVICE)\n",
    "print(\"we will classify :{}\".format(n_classes))\n",
    "print(simple_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запустим обучение сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:38.727578Z",
     "iopub.status.busy": "2021-11-15T12:18:38.727267Z",
     "iopub.status.idle": "2021-11-15T12:18:38.930416Z",
     "shell.execute_reply": "2021-11-15T12:18:38.929434Z",
     "shell.execute_reply.started": "2021-11-15T12:18:38.727535Z"
    }
   },
   "outputs": [],
   "source": [
    "if val_dataset is None:\n",
    "    val_dataset = SimpsonsDataset(val_files, mode='val')\n",
    "    \n",
    "# train_dataset = SimpsonsDataset(train_files, mode='train')\n",
    "train_dataset = SimpsonsDataset(new_train_files, mode='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:18:38.932463Z",
     "iopub.status.busy": "2021-11-15T12:18:38.932164Z",
     "iopub.status.idle": "2021-11-15T12:25:36.166423Z",
     "shell.execute_reply": "2021-11-15T12:25:36.165485Z",
     "shell.execute_reply.started": "2021-11-15T12:18:38.932422Z"
    }
   },
   "outputs": [],
   "source": [
    "history = train(train_dataset, val_dataset, model=simple_cnn, epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:36.169125Z",
     "iopub.status.busy": "2021-11-15T12:25:36.168541Z",
     "iopub.status.idle": "2021-11-15T12:25:36.175367Z",
     "shell.execute_reply": "2021-11-15T12:25:36.174124Z",
     "shell.execute_reply.started": "2021-11-15T12:25:36.169081Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = train(train_dataset, val_dataset, model=simple_cnn, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:36.177639Z",
     "iopub.status.busy": "2021-11-15T12:25:36.177003Z",
     "iopub.status.idle": "2021-11-15T12:25:36.189688Z",
     "shell.execute_reply": "2021-11-15T12:25:36.188402Z",
     "shell.execute_reply.started": "2021-11-15T12:25:36.177578Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, acc, val_loss, val_acc = zip(*history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:36.192109Z",
     "iopub.status.busy": "2021-11-15T12:25:36.191553Z",
     "iopub.status.idle": "2021-11-15T12:25:36.490927Z",
     "shell.execute_reply": "2021-11-15T12:25:36.489883Z",
     "shell.execute_reply.started": "2021-11-15T12:25:36.192017Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(loss, label=\"train_loss\")\n",
    "plt.plot(val_loss, label=\"val_loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Хорошо бы понять, как сделать сабмит. У нас есть сеть и методы eval у нее, которые позволяют перевести сеть в режим предсказания. Стоит понимать, что у нашей модели на последнем слое стоит softmax, которые позволяет получить вектор вероятностей того, что объект относится к тому или иному классу. Давайте воспользуемся этим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:36.492743Z",
     "iopub.status.busy": "2021-11-15T12:25:36.492359Z",
     "iopub.status.idle": "2021-11-15T12:25:36.501806Z",
     "shell.execute_reply": "2021-11-15T12:25:36.500164Z",
     "shell.execute_reply.started": "2021-11-15T12:25:36.492669Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_one_sample(model, inputs, device=DEVICE):\n",
    "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        model.eval()\n",
    "        logit = model(inputs).cpu()\n",
    "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:36.504887Z",
     "iopub.status.busy": "2021-11-15T12:25:36.504458Z",
     "iopub.status.idle": "2021-11-15T12:25:36.536819Z",
     "shell.execute_reply": "2021-11-15T12:25:36.535844Z",
     "shell.execute_reply.started": "2021-11-15T12:25:36.504838Z"
    }
   },
   "outputs": [],
   "source": [
    "random_characters = int(np.random.uniform(0,1000))\n",
    "ex_img, true_label = val_dataset[random_characters]\n",
    "probs_im = predict_one_sample(simple_cnn, ex_img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:36.541295Z",
     "iopub.status.busy": "2021-11-15T12:25:36.540698Z",
     "iopub.status.idle": "2021-11-15T12:25:36.716496Z",
     "shell.execute_reply": "2021-11-15T12:25:36.715374Z",
     "shell.execute_reply.started": "2021-11-15T12:25:36.541253Z"
    }
   },
   "outputs": [],
   "source": [
    "idxs = list(map(int, np.random.uniform(0,1000, 20)))\n",
    "imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n",
    "\n",
    "probs_ims = predict(simple_cnn, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:36.719842Z",
     "iopub.status.busy": "2021-11-15T12:25:36.719262Z",
     "iopub.status.idle": "2021-11-15T12:25:36.725951Z",
     "shell.execute_reply": "2021-11-15T12:25:36.724714Z",
     "shell.execute_reply.started": "2021-11-15T12:25:36.719797Z"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:36.728238Z",
     "iopub.status.busy": "2021-11-15T12:25:36.727832Z",
     "iopub.status.idle": "2021-11-15T12:25:36.855349Z",
     "shell.execute_reply": "2021-11-15T12:25:36.854445Z",
     "shell.execute_reply.started": "2021-11-15T12:25:36.728196Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(probs_ims,-1)\n",
    "\n",
    "actual_labels = [val_dataset[id][1] for id in idxs]\n",
    "\n",
    "# preds_class = [label_encoder.classes_[i] for i in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:37.042773Z",
     "iopub.status.busy": "2021-11-15T12:25:37.042105Z",
     "iopub.status.idle": "2021-11-15T12:25:37.054754Z",
     "shell.execute_reply": "2021-11-15T12:25:37.053246Z",
     "shell.execute_reply.started": "2021-11-15T12:25:37.042738Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(actual_labels, y_pred.tolist(),average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сделаем классную визуализацию, чтобы посмотреть насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:37.057376Z",
     "iopub.status.busy": "2021-11-15T12:25:37.057024Z",
     "iopub.status.idle": "2021-11-15T12:25:39.280641Z",
     "shell.execute_reply": "2021-11-15T12:25:39.278375Z",
     "shell.execute_reply.started": "2021-11-15T12:25:37.057332Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1000))\n",
    "    im_val, label = val_dataset[random_characters]\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    \n",
    "    \n",
    "\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label,plt_ax=fig_x)\n",
    "    \n",
    "    actual_text = \"Actual : {}\".format(img_label)\n",
    "            \n",
    "    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n",
    "    font0 = FontProperties()\n",
    "    font = font0.copy()\n",
    "    font.set_family(\"fantasy\")\n",
    "    prob_pred = predict_one_sample(simple_cnn, im_val.unsqueeze(0))\n",
    "    predicted_proba = np.max(prob_pred)*100\n",
    "    y_pred = np.argmax(prob_pred)\n",
    "    \n",
    "    predicted_label = label_encoder.classes_[y_pred]\n",
    "    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n",
    "    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n",
    "            \n",
    "    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n",
    "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуйте найти те классы, которые сеть не смогла расспознать. Изучите данную проблему, это понадобится в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:39.283289Z",
     "iopub.status.busy": "2021-11-15T12:25:39.282411Z",
     "iopub.status.idle": "2021-11-15T12:25:47.301750Z",
     "shell.execute_reply": "2021-11-15T12:25:47.300766Z",
     "shell.execute_reply.started": "2021-11-15T12:25:39.283251Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "probs = predict(simple_cnn, test_loader)\n",
    "\n",
    "\n",
    "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
    "test_filenames = [path.name for path in test_dataset.files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:47.304725Z",
     "iopub.status.busy": "2021-11-15T12:25:47.304042Z",
     "iopub.status.idle": "2021-11-15T12:25:47.312681Z",
     "shell.execute_reply": "2021-11-15T12:25:47.311740Z",
     "shell.execute_reply.started": "2021-11-15T12:25:47.304667Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'Id':test_filenames, 'Expected':preds}\n",
    "sub_0 = pd.DataFrame(data=d)\n",
    "sub_0.to_csv('sub_0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:47.335374Z",
     "iopub.status.busy": "2021-11-15T12:25:47.335088Z",
     "iopub.status.idle": "2021-11-15T12:25:47.359815Z",
     "shell.execute_reply": "2021-11-15T12:25:47.358885Z",
     "shell.execute_reply.started": "2021-11-15T12:25:47.335328Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('/kaggle/working/sub_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:47.361639Z",
     "iopub.status.busy": "2021-11-15T12:25:47.361335Z",
     "iopub.status.idle": "2021-11-15T12:25:48.169761Z",
     "shell.execute_reply": "2021-11-15T12:25:48.168545Z",
     "shell.execute_reply.started": "2021-11-15T12:25:47.361587Z"
    }
   },
   "outputs": [],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:48.172521Z",
     "iopub.status.busy": "2021-11-15T12:25:48.171874Z",
     "iopub.status.idle": "2021-11-15T12:25:48.233674Z",
     "shell.execute_reply": "2021-11-15T12:25:48.231653Z",
     "shell.execute_reply.started": "2021-11-15T12:25:48.172456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Освободим кэж видеопамяти\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:48.236420Z",
     "iopub.status.busy": "2021-11-15T12:25:48.235799Z",
     "iopub.status.idle": "2021-11-15T12:25:48.245089Z",
     "shell.execute_reply": "2021-11-15T12:25:48.243801Z",
     "shell.execute_reply.started": "2021-11-15T12:25:48.236369Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:48.248008Z",
     "iopub.status.busy": "2021-11-15T12:25:48.247225Z",
     "iopub.status.idle": "2021-11-15T12:25:49.395997Z",
     "shell.execute_reply": "2021-11-15T12:25:49.394478Z",
     "shell.execute_reply.started": "2021-11-15T12:25:48.247961Z"
    }
   },
   "outputs": [],
   "source": [
    "model_google = models.googlenet(pretrained=True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:49.400264Z",
     "iopub.status.busy": "2021-11-15T12:25:49.399070Z",
     "iopub.status.idle": "2021-11-15T12:25:49.448878Z",
     "shell.execute_reply": "2021-11-15T12:25:49.444293Z",
     "shell.execute_reply.started": "2021-11-15T12:25:49.400122Z"
    }
   },
   "outputs": [],
   "source": [
    "child_counter = 0\n",
    "for child in model_google.children():\n",
    "    print(\" child\", child_counter, \"is:\")\n",
    "    print(child)\n",
    "    child_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:49.451231Z",
     "iopub.status.busy": "2021-11-15T12:25:49.450862Z",
     "iopub.status.idle": "2021-11-15T12:25:49.464000Z",
     "shell.execute_reply": "2021-11-15T12:25:49.461333Z",
     "shell.execute_reply.started": "2021-11-15T12:25:49.451188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Выключаем подсчет градиентов для слоев, которые не будем обучать\n",
    "for i, child in enumerate(model_google.children()):\n",
    "    if i not in [x for x in range(9,17)]: # Заморозим первые 8 слоев\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "model_google.fc = nn.Sequential(nn.Linear(1024,42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:49.472898Z",
     "iopub.status.busy": "2021-11-15T12:25:49.470964Z",
     "iopub.status.idle": "2021-11-15T12:25:49.496104Z",
     "shell.execute_reply": "2021-11-15T12:25:49.495232Z",
     "shell.execute_reply.started": "2021-11-15T12:25:49.472722Z"
    }
   },
   "outputs": [],
   "source": [
    "model_google = model_google.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T12:25:49.497990Z",
     "iopub.status.busy": "2021-11-15T12:25:49.497510Z",
     "iopub.status.idle": "2021-11-15T13:09:17.868483Z",
     "shell.execute_reply": "2021-11-15T13:09:17.867392Z",
     "shell.execute_reply.started": "2021-11-15T12:25:49.497927Z"
    }
   },
   "outputs": [],
   "source": [
    "history = train(train_dataset, val_dataset, model=model_google, epochs=15,  \n",
    "                batch_size=64\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:17.870721Z",
     "iopub.status.busy": "2021-11-15T13:09:17.870206Z",
     "iopub.status.idle": "2021-11-15T13:09:18.085326Z",
     "shell.execute_reply": "2021-11-15T13:09:18.084302Z",
     "shell.execute_reply.started": "2021-11-15T13:09:17.870677Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# сохранить веса нашей нейросети model\n",
    "model_pre_weights = copy.deepcopy(model_google.state_dict())\n",
    "torch.save(model_pre_weights, \"path_to\\\\model_pre_weights.pth\")\n",
    "model_google.load_state_dict(torch.load(\"path_to\\\\model_pre_weights.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.087499Z",
     "iopub.status.busy": "2021-11-15T13:09:18.087015Z",
     "iopub.status.idle": "2021-11-15T13:09:18.093062Z",
     "shell.execute_reply": "2021-11-15T13:09:18.091019Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.087454Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Включаем все слои!!!\n",
    "# for child in model_google.children():\n",
    "#     for param in child.parameters():\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.095463Z",
     "iopub.status.busy": "2021-11-15T13:09:18.094857Z",
     "iopub.status.idle": "2021-11-15T13:09:18.103952Z",
     "shell.execute_reply": "2021-11-15T13:09:18.102836Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.095418Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.105953Z",
     "iopub.status.busy": "2021-11-15T13:09:18.105324Z",
     "iopub.status.idle": "2021-11-15T13:09:18.115628Z",
     "shell.execute_reply": "2021-11-15T13:09:18.114422Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.105799Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = train(train_dataset, val_dataset, model=model_google, epochs=19, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.118097Z",
     "iopub.status.busy": "2021-11-15T13:09:18.117096Z",
     "iopub.status.idle": "2021-11-15T13:09:18.127111Z",
     "shell.execute_reply": "2021-11-15T13:09:18.125989Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.118053Z"
    }
   },
   "outputs": [],
   "source": [
    "# # сохранить веса нашей нейросети model\n",
    "# model_25epoch_weights = copy.deepcopy(model_google.state_dict())\n",
    "# torch.save(model_25epoch_weights, \"path_to\\\\model_25epoch_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.131609Z",
     "iopub.status.busy": "2021-11-15T13:09:18.131195Z",
     "iopub.status.idle": "2021-11-15T13:09:18.137876Z",
     "shell.execute_reply": "2021-11-15T13:09:18.136827Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.131547Z"
    }
   },
   "outputs": [],
   "source": [
    "# # загружаем сохраненное состояние весов нейросети\n",
    "# model_google.load_state_dict(torch.load(\"path_to\\\\model_25epoch_weights.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заморозка первых слоев положительно сказывается на быстродействии и качестве модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.153707Z",
     "iopub.status.busy": "2021-11-15T13:09:18.152394Z",
     "iopub.status.idle": "2021-11-15T13:09:18.446731Z",
     "shell.execute_reply": "2021-11-15T13:09:18.445822Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.153660Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(loss, label=\"train_loss\")\n",
    "plt.plot(val_loss, label=\"val_loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.729642Z",
     "iopub.status.busy": "2021-11-15T13:09:18.729308Z",
     "iopub.status.idle": "2021-11-15T13:09:18.735520Z",
     "shell.execute_reply": "2021-11-15T13:09:18.734330Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.729599Z"
    }
   },
   "outputs": [],
   "source": [
    "probs_ims = predict(model_google, imgs)\n",
    "y_pred = np.argmax(probs_ims,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.737829Z",
     "iopub.status.busy": "2021-11-15T13:09:18.737340Z",
     "iopub.status.idle": "2021-11-15T13:09:18.753162Z",
     "shell.execute_reply": "2021-11-15T13:09:18.752092Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.737784Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score(actual_labels, y_pred.tolist(),average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На довольно небольшом количестве эпох удалось получить достойный результат 0.95\n",
    "## На лидерборде выбили **0.96068**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.755307Z",
     "iopub.status.busy": "2021-11-15T13:09:18.754932Z",
     "iopub.status.idle": "2021-11-15T13:09:18.761180Z",
     "shell.execute_reply": "2021-11-15T13:09:18.760215Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.755251Z"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:18.763807Z",
     "iopub.status.busy": "2021-11-15T13:09:18.763073Z",
     "iopub.status.idle": "2021-11-15T13:09:21.049643Z",
     "shell.execute_reply": "2021-11-15T13:09:21.048795Z",
     "shell.execute_reply.started": "2021-11-15T13:09:18.763760Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1000))\n",
    "    im_val, label = val_dataset[random_characters]\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    \n",
    "    \n",
    "\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label,plt_ax=fig_x)\n",
    "    \n",
    "    actual_text = \"Actual : {}\".format(img_label)\n",
    "            \n",
    "    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n",
    "    font0 = FontProperties()\n",
    "    font = font0.copy()\n",
    "    font.set_family(\"fantasy\")\n",
    "    prob_pred = predict_one_sample(model_google, im_val.unsqueeze(0))\n",
    "    predicted_proba = np.max(prob_pred)*100\n",
    "    y_pred = np.argmax(prob_pred)\n",
    "    \n",
    "    predicted_label = label_encoder.classes_[y_pred]\n",
    "    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n",
    "    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n",
    "            \n",
    "    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n",
    "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:21.052263Z",
     "iopub.status.busy": "2021-11-15T13:09:21.051287Z",
     "iopub.status.idle": "2021-11-15T13:09:25.264894Z",
     "shell.execute_reply": "2021-11-15T13:09:25.263978Z",
     "shell.execute_reply.started": "2021-11-15T13:09:21.052208Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "probs = predict(model_google, test_loader)\n",
    "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
    "test_filenames = [path.name for path in test_dataset.files]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:25.267004Z",
     "iopub.status.busy": "2021-11-15T13:09:25.266691Z",
     "iopub.status.idle": "2021-11-15T13:09:25.275789Z",
     "shell.execute_reply": "2021-11-15T13:09:25.274614Z",
     "shell.execute_reply.started": "2021-11-15T13:09:25.266962Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'Id':test_filenames, 'Expected':preds}\n",
    "sub_1 = pd.DataFrame(data=d)\n",
    "sub_1.to_csv('sub_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T13:09:25.292770Z",
     "iopub.status.busy": "2021-11-15T13:09:25.291670Z",
     "iopub.status.idle": "2021-11-15T13:09:25.311579Z",
     "shell.execute_reply": "2021-11-15T13:09:25.310640Z",
     "shell.execute_reply.started": "2021-11-15T13:09:25.292723Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('sub_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
